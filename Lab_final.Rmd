---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2'
geometry: margin=1in
output:
  github_document: default
---
# Introduction 
## The Keeling Curve

In the 1950s, the geochemist Charles David Keeling observed a seasonal pattern in the amount of carbon dioxide present in air samples collected over the course of several years. He was able to attribute this pattern to the variation in global rates of photosynthesis throughout the year, caused by the difference in land area and vegetation cover between the Earth's northern and southern hemispheres. 

In 1958 Keeling began continuous monitoring of atmospheric carbon dioxide concentrations from the Mauna Loa Observatory in Hawaii. Mauna Loa was chosen as a long-term monitoring site due to its remote location far from continents and its lack of vegetation. Keeling soon observed a trend increase in carbon dioxide (CO2) levels in addition to the seasonal cycle. He was able to attribute this trend increase to growth in global rates of fossil fuel combustion. 

Since CO2 is a greenhouse gas, higher levels of CO2 can lead to a warmer planet, causing climate change. Climate change can result in more frequent and severe weather events such as floods, cyclones, typhoons, and wildfires. It can also lead to a decrease in crop yields and put many animal species at risk of extinction.

Our team will analyze the CO2 average parts per million recorded from Manua Loa since 1957 to the present (1997). 

The apparent increasing trend could be dismissed as a transient stochastic phenomenon, if so, it should be possible to model the trend using stochastic functions and without the use of deterministic functions. 

Our team will fit the data using stochastic ARIMA models, and deterministic Linear Time Trend models and and use diagnostics to determine which one best fits the data. Our team will also forecast what the expected CO2 levels wil be in the 2020 and 2022, if the same trends continue to hold.

Our exercise will aid the scientific community to decide if the increasing trend can be dismissed or should further research be made. Furthermore, our forecasts will aid policy makers to take the steps to prevent the increasing trend of CO2 levels in the atmosphere. 

```{r load packages, echo = FALSE, message = FALSE, warning = FALSE }
library(tidyverse)
library(tsibble)
library(latex2exp)
library(lubridate)
library(forecast)
library(stats)
library(feasts)
library(patchwork)
library(ggplot2)
library(grid)
library(gridExtra)
library(fable)
library(scales)
library(sandwich)
library(lmtest)
library(blsR)
library(magrittr)
library(corrr)


theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

```{r plot the keeling curve, echo = FALSE}
tsibble::as_tsibble(co2) %>%
  ggplot() + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    subtitle = 'The "Keeling Curve"',
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
```
\newpage


## CO2 data
### Background and Exploratory Data Analysis (EDA)
#### Background
The data is the accumulation of carbon dioxide in the Earth's atmosphere based on continuous measurements taken at the Mauna Loa Observatory on the island of Hawaii from 1959 to the present day. In addition to the summit's lack of vegatation shielding it from the effects of local trends in CO2 emmissions, the altitude (3,400 meter) of the site is well situated to measure representative air masses for a large area. Furthermore, Keeling and his collaborators measured the incoming ocean breeze above the thermal inversion layer to minimize local contamination from volcanic vents. The data is normalized to remove any influence from local contamination.

The CO2 data is collected by a CO2 analyzer that uses a technique called "Cavity Ring-Down Spectroscopy (CRDS). The measurements are made with an infrared spectrophotometer known as a non-dispersive infrared sensor, which is calibrated using World Meteorological Organization standards. The site has used the same sensor type since 1959. In addition, the CO2 measurements are compared with other individual measurements to ensure the accuracy of the measured data.


#### Exploratory Data Analysis (EDA)
```{r EDA1, echo = FALSE}
co2.mthly <- co2

df <- as_tsibble(co2.mthly)
df <- df %>% mutate(
  value = round(value, 2), 
  log_value = log(value)
)

df_add <- df %>% model(stl = STL(value))
df_mult <- df %>% model(stl = STL(log_value)) 

p1a1 <- components(df_add) %>% 
  as_tsibble() %>% 
  autoplot(value, colour = "gray") + geom_line(aes(y = trend), color = "#D55E00") + 
  labs(y = "CO2 Part per Million", x = "Time", title = "Monthly CO2 Mole PPM")

p1a2 <- components(df_mult) %>% 
    as_tsibble() %>% 
  autoplot(log_value, colour = "gray") + geom_line(aes(y = trend), color = "#D55E00") + 
  labs(y = "Log of CO2 Part per Million", x = "Time", title = "Log of Monthly CO2 Mole PPM")

grid.arrange(p1a1, p1a2, nrow = 1, ncol = 2)

```
The team performed exploratory data analysis (EDA) to understand the timeseries data of CO2 mole fraction (part per million - ppm) at Mauna Loa. In the above, the left plot shows the trend between the CO2 measurements with time and on the right the logarithm of the CO2 measurements with time. The trend lines were generated using additive (left) and multiplicative (right) decomposition methods. The left plot suggests an approximate constant growth rate, and thus an additive decomposition method may be a sufficient for this problem. However, the data was fit with both methods and used the diagnostic statistics to determine which method is a more appropriate.  

```{r EDA1_2, echo = FALSE}

p1a3 <- df_add %>% components() %>% autoplot() 
p1a4 <- df_add %>% components() %>% ACF(remainder) %>% autoplot() + labs(titles = "Residuals of additive composition") 
p1a5 <- df_mult %>% components() %>% autoplot() 
p1a6 <- df_mult %>% components() %>% ACF(remainder) %>% autoplot() + labs(title = "Residuals of multiplicative composition")

#grid.arrange(p1a3, p1a4, p1a5, p1a6, nrow = 2, ncol = 2) 
grid.arrange(p1a3, p1a4, nrow = 1, ncol = 2) 
```
The second plot above shows the actual decomposition using the additive method, the autocorrelation (ACF) plot of the residuals. The linear trend portion suggests that from 1959 to 1997, the CO2 level increases about 40 ppms, the seasonality portion suggests that the CO2 mole fraction varies by 2 ppm depending on season. The ACF plots show that although the residuals seem to be stationary, they do not follow a white noise signal (there are significant lags within the plot), suggesting a linear time and seasonal model may not be sufficient to fit the data. The plots of the multiplicative method show the the same results, therefore they are omitted. 

As noted above the seasonal component appears to have a mode and antimode of -2 ppm to 2 ppm, with a slight increase in amplitude over time. This increase is an interesting finding that we will explore next.  

```{r EDA1_3, echo = FALSE}
df_add %>% components() %>% gg_subseries(season_year) + labs(x = "Month of Year" , y = "Seasonal CO2 Changes", title = "Seasonal Component of the CO2 measurements at Mauna Loa") 
```
A seasonal subseries plot (above) facets the time series by each season in the seasonal period. This function is particularly useful in identifying changes in the seasonal pattern over time. From the plot above we can see that from 1960 to 1990 the mode and antimode have increased over the years, this is particulary visible in the month of May, August, September and October. We will explore if this increase in amplitude affects the overall growth trend. 

```{r EDA2_2, echo = FALSE}
#insert slopes for each decade
#df60 is for the decade of 1960, df70 for 1970, etc..
df60<-df%>%filter(index > yearmonth('1959-12-31') & (index < yearmonth('1969-12-31')) )
df70<-df%>%filter(index > yearmonth('1969-12-31')& (index < yearmonth('1979-12-31')) )
df80<-df%>%filter(index > yearmonth('1979-12-31')& (index < yearmonth('1989-12-31')) ) 


#fit each data set
model60 <-lm(df60$value ~ df60$index)
model70 <-lm(df70$value ~ df70$index)
model80 <-lm(df80$value ~ df80$index)

#generate plot points for 60, 70, etc...
newdata <- data.frame(time = seq(min(df60$index), max(df80$index), length.out = 119))
newdata$decade60 <- predict(model60, newdata)
newdata$decade70 <- predict(model70, newdata)
newdata$decade80 <- predict(model80, newdata)

slope_g <- ggplot(newdata, aes(time)) + 
  geom_line(aes(y = decade60, color = "slope line m1960")) +
  geom_line(aes(y = decade70, color = "slope line m1970")) +
  geom_line(aes(y = decade80, color = "slope line m1980")) +
  labs(color = "decade")

decade <- c(1960, 1970,1980)
slope <- c(round(coef(model60)["df60$index"]*1000,2),
           round(coef(model70)["df70$index"]*1000,2),
           round(coef(model80)["df80$index"]*1000,2)
           )

df_coef <- data.frame(decade, slope)

#head(df_coef)

slope_scatter<-ggplot(df_coef, aes(x = decade, y = slope)) +
  geom_point() +
  labs(x = "Decade", y = "Slope", title = "Slope vs Decade")

grid.arrange(slope_g , slope_scatter, nrow = 1, ncol = 2) 
```
The plot on the left is each decade fitted to a linear model. We have complete decades from 1960 up to the decade of 1980. From the plot we can see that the slope is increasing. On the right is the scatter plot of the slope for each decade. The rate of growth increased from an average of 2.2 PPM to 4.4 PPM over three decades. We expect an exponential model to better fit the data. The CO2 trend not only includes a seasonal component with an increasing amplitude but also an increasing slope over time. It would be satisfying to find out if those two components are correlated. That is beyond the scope of this analysis.

```{r EDA2, echo = FALSE}

#df %>% gg_tsdisplay(value, plot_type = 'partial')

#df %>% gg_tsdisplay(difference(value), plot_type = 'partial')

#df %>% gg_tsdisplay(difference(difference(value),12), plot_type = 'partial')

df %>% gg_tsdisplay(log(value), plot_type = 'partial')



```
The first plot shows the ACF and PACF plots of the raw data after its log transformation. The ACF portion of this plot shows a strong trend. The PACF plot shows seasonality every 12th lag, and some cyclical components.

```{r EDA2_1, warning= FALSE, echo = FALSE}

#df %>% gg_tsdisplay(difference(log(value)), plot_type = 'partial')

df %>% gg_tsdisplay(difference(difference(log(value)),12), plot_type = 'partial')

```

The team performed a series of transformation steps to remove the trend and seasonality component from the CO2 timeseries data.  The team took a difference of the CO2 measurements in order to remove the trend component. The ACF and PACF portion of the first order differencing of the CO2 measurements showed that a seasonality component remained at every 12 lags and the ACF portion was very distinct from white noise. To remove the seasonality component, the team performed a further differencing at every 12 lags of the dataset. The plot above shows that the dataset after two differencing is closer to random white noise. The PACF portion shows that the autoregressive term at lag 1 and lag 12 is significant but the level of significance is lower compared to the moving average term at lag 1 and 12, this suggests that we can use a ma1 and seasonal ma1 model to fit the data. This information will be using when fitting the ARIMA model. The team performed the analysis on the additive and multiplicative model, but we are showing the results for the multiplicative model only, as the additive model results are exactly the same. 

## Linear time trend model
#### Fitting the Data to an LTTM 

```{r Linear time trend model, echo=FALSE, warning=FALSE}
add.mdls <- df %>% 
  model(add_lin = TSLM(value ~ trend()),
        add_quad = TSLM(value ~ trend() + I(trend()^2)),
        add_lin_sea = TSLM(value ~ trend() + season()),
        add_quad_sea = TSLM(value ~ trend() + I(trend()^2) + season()))

add.mdls %>% report()

mul.mdls <- df %>% 
  model(mul_lin = TSLM(log_value ~ trend()),
        mul_quad = TSLM(log_value ~ trend() + I(trend()^2)),
        mul_lin_sea = TSLM(log_value ~ trend() + season()),
        mul_quad_sea = TSLM(log_value ~ trend() + I(trend()^2) + season()))
mul.mdls %>% report()

mul.quad.sea <- df %>% 
  model(trend_model = TSLM(log_value ~ trend() + I(trend()^2) + season()))
mul.quad.sea %>% report()

```
The team fit the data using four modeling combinations: linear trend only, linear with quadratic trend, linear trend with seasonal, and linear trend with quadratic trend and seasonal. For each modeling combination, the team used both decomposition methods to fit the data. The team selected the model with the lowest corrected Akaike information criterion (AIC). Based on the information presented in the above tables, and as expected, the model using multiplicative decomposition methodology and including the linear trend, quadratic trend and seasonal terms is the best model out of the eight models. The summary table shows that all coefficients were statistically different from 0. The adjusted R square of the model is 0.9976, which indicates that more than 99% of the response variance is explained in this model. 


```{r residual analysis linear model, warning = FALSE, echo = FALSE}
mul.quad.sea %>% gg_tsresiduals()

p2a1 <- augment(mul.quad.sea) %>% 
  ggplot(aes(x = .fitted, y = .innov)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  scale_x_log10()
grid.arrange(p2a1, nrow = 1, ncol = 1)

```

The team also conducted a residual analysis on the selected LTTM. The residual ACF plot shows that the residuals do not follow a white noise signal and is not a stationary timeseries. The residual against fitted value plot also shows that there is a relationship between the model residuals and the fitted value, which indicates that there are confounding variables.


```{r residual analysis linear model2, warning = FALSE, echo = FALSE}
p2a2 <- augment(mul.quad.sea) %>% mutate(
  month = month(index, label = TRUE)
) %>% ggplot(aes(x = month, y = .innov)) + geom_boxplot()

grid.arrange(p2a2, nrow = 1, ncol = 1)


augment(mul.quad.sea) %>% features(.innov, ljung_box, dof = 2, lag = 200)

```
 Moreover, the ljung-box test (p-value less than 0.05) also shows that the residuals of the model exhibit a serial correlation. The diagnostics indicate that structure remains in the residual data, however a model with such residuals can be tolerated if the model provides useful forecasts. The team decided not to add more variables because of concerns with overfitting and as a consequence poor forecasting.

#### Forecasting with a LTT model 

```{r forecast, warning =FALSE, echo = FALSE}
future.df <- new_data(df, n = 276)

fx2020 <- mul.quad.sea %>% forecast(new_data = future.df)
fx2020 <- fx2020 %>% mutate(
  log_value = exp(log_value),
  .mean = exp(.mean) 
)

df2 <- df %>% mutate(
  log_value = exp(log_value)
)
fx2020 %>% autoplot(df2) + labs(x = "Time", y = "CO2 Mole Fraction (PPM)", title = "CO2 Measurement at Mauna Loa from 1997 to 2020")

fx2020 %>% hilo(90) %>% tail
```
The team used the selected model to generate CO2 mole fraction forecasts from December 1997 to December 2020 (as shown in the above graph). The generated forecast indicates a similar pattern of growth for the CO2 level in the atmosphere. By 2020, the CO2 mole fraction is predicted to reach approximately 417 ppm with a 90% confidence interval (CI) between 415 and 419 ppm. 

## ARIMA times series model 
#### Fitting the Data to an ARIMA model 

We will now choose an ARIMA model to fit to the time series.

```{r unit root, warning = FALSE, echo = FALSE} 
df %>% features(value, unitroot_ndiffs)
df %>% features(value, unitroot_nsdiffs)
df %>% features(difference(difference(value),12), unitroot_kpss)
```

Following the initial analysis done in the EDA section, the team used a unit root test to determine the number of differences (both seasonal and non-seasonal) to make the CO2 timeseries stationary. The unit root test results show that it requires one seasonal and one non-seasonal difference to make the timeseries stationary. These results are in agreement with our findings in the explanatory data analysis section. 

The KPSS test of the CO2 timeseries after applying the differences (at lag 1 and lag 12) shows a p-value of 0.1, which is greater than 0.05, therefore we fail to reject the null hypothesis that the time series is stationary after two differencing. 

The ACF portion in the EDA showed that we can expect to use multiple ma1 non-seasonal terms and a seasonal MA1 model to fit the data, the EDA did not indicate a need for an AR term.

```{r ARIMA model, warning = FALSE, echo = FALSE}
ari.fit <- df %>% 
  model(ARIMA111111 = ARIMA(log(value) ~ pdq(1,1,1) + PDQ(1,1,1)),
        ARIMA111211 = ARIMA(log(value)  ~ pdq(1,1,1) + PDQ(2,1,1)),
        ARIMA211211 = ARIMA(log(value)  ~ pdq(2,1,1) + PDQ(2,1,1)),
        ARIMA112112 = ARIMA(log(value)  ~ pdq(1,1,2) + PDQ(1,1,2)), 
        ARIMA112111 = ARIMA(log(value)  ~ pdq(1,1,2) + PDQ(1,1,1)),
        ARIMA111112 = ARIMA(log(value)  ~ pdq(1,1,1) + PDQ(1,1,2)),
        ARIMA013011 = ARIMA(log(value)  ~ pdq(0,1,3) + PDQ(0,1,1)),
        auto = ARIMA(log(value), stepwise = FALSE, approx = FALSE)
        )

ari.fit %>% pivot_longer(everything(), names_to = "Model name", values_to = "Orders")

glance(ari.fit) |> arrange(AIC) |> select(.model:AIC)
```

Based on the results of testing out different model combination, the SARIMA model with one seasonal and one non-seasonal differencing, three non-seasonal moving average terms and one seasonal moving average term seems to be the model with the best performance (lowest AIC), which is consistent with our EDA analysis. 

```{r residual analysis arima, warning = FALSE, echo = FALSE}
ari.fit %>% select(ARIMA013011) %>% gg_tsresiduals(lag = 36)
augment(ari.fit) %>%
  features(.innov, ljung_box, lag=200, dof=4)

```
The residual analysis of the selected model shows that the residuals timeseries is white noise signal. The ljung-box test result shows that all selected models have p-value greater than 0.05, which suggests that the residuals of the selected model is stationary. The ARIMA model accounts for the structure of the data better than our LTTM model. ARIMA models are more flexible then LTTM as they can capture more complex patterns in the data.

#### Forecasting with an ARIMA model

```{r forecast arima, warning= FALSE, echo = FALSE}
ari.fit %>% forecast(h = 300) %>% filter(.model == 'ARIMA013011') %>% autoplot(df)

ari.fit %>% forecast(h = 300) %>% filter(.model == 'ARIMA013011') %>% hilo(90) %>% tail
```

The team used the selected model to generate CO2 level in the atmosphere to December 2022. Based on the generated forecast, in December 2022, the forecasted CO2 level will be approximately 402 ppm with a 90% CI between 389 and 416 ppm. This result is lower than the forecast using the LTTM model which already forecasts 417 ppm by 2020, two years before. 

## Forecast atmospheric CO2 growth 
#### Comparing LTTM and ARIMA Forecasts 

```{r generate hilo and 2100 forecast, echo = FALSE}
future.df.2100 <- new_data(df, n = 1236)
fx2100 <- mul.quad.sea %>% forecast(new_data = future.df.2100)
fx2100 <- fx2100 %>% mutate(
  log_value = exp(log_value),
  .mean = exp(.mean) 
)

# Predict when CO2 level reaches 420 
fx2100.90hilo.lm <- fx2100 %>% hilo(90) %>% unpack_hilo("90%") 
fx2100.1st420.lm <- fx2100.90hilo.lm %>% filter(`90%_upper`>= 420) %>% filter(row_number() == 1) %>% select(index)
fx2100.lst420.lm <- fx2100.90hilo.lm %>% filter(`90%_lower` < 421) %>% filter(row_number() == n()) %>% select(index)
fx2100.avg420.lm1 <- fx2100.90hilo.lm %>% filter(.mean >= 420) %>% filter(row_number() == 1) %>% select(index)
fx2100.avg420.lm2 <- fx2100.90hilo.lm %>% filter(.mean < 421) %>% filter(row_number() == n()) %>% select(index)

fx2100.90hilo.ari <- ari.fit %>% forecast(h = 1236) %>% filter(.model == 'ARIMA013011') %>% hilo(90) %>% unpack_hilo("90%") 
fx2100.1st420.ari <- fx2100.90hilo.ari %>% filter(`90%_upper` >= 420) %>% filter(row_number() == 1) %>% select(index) 
fx2100.lst420.ari <- fx2100.90hilo.ari %>% filter(`90%_lower` < 421) %>% filter(row_number() == n()) %>% select(index) 
fx2100.avg420.ari1 <- fx2100.90hilo.ari %>% filter(.mean >= 420) %>% filter(row_number() == 1) %>% select(index) 
fx2100.avg420.ari2 <- fx2100.90hilo.ari %>% filter(.mean < 421) %>% filter(row_number() == n()) %>% select(index) 

# Predict when CO2 level reaches 500 
fx2100.1st500.lm <- fx2100.90hilo.lm %>% filter(`90%_upper`>= 500) %>% filter(row_number() == 1) %>% select(index)
fx2100.lst500.lm <- fx2100.90hilo.lm %>% filter(`90%_lower` < 501) %>% filter(row_number() == n()) %>% select(index)
fx2100.avg500.lm1 <- fx2100.90hilo.lm %>% filter(.mean >= 500) %>% filter(row_number() == 1) %>% select(index)
fx2100.avg500.lm2 <- fx2100.90hilo.lm %>% filter(.mean < 501) %>% filter(row_number() == n()) %>% select(index)

fx2100.1st500.ari <- fx2100.90hilo.ari %>% filter(`90%_upper` >= 500) %>% filter(row_number() == 1) %>% select(index) 
fx2100.lst500.ari <- fx2100.90hilo.ari %>% filter(`90%_lower` < 501) %>% filter(row_number() == n()) %>% select(index) 
fx2100.avg500.ari1 <- fx2100.90hilo.ari %>% filter(.mean >= 500) %>% filter(row_number() == 1) %>% select(index) 
fx2100.avg500.ari2 <- fx2100.90hilo.ari %>% filter(.mean < 501) %>% filter(row_number() == n()) %>% select(index) 


# Generate forecast in 2100 
fx2100.lm <- fx2100.90hilo.lm %>% index_by(
  year = year(index)
) %>% summarise(
  sumCO2= mean(.mean)) %>% filter(row_number() == n()) %>% as_tibble() %>% select(sumCO2)


fx2100.ari <- fx2100.90hilo.ari %>% index_by(
  year = year(index)
) %>% summarise( 
  sumCO2 = mean(.mean)) %>% filter(row_number() == n()) %>% as_tibble() %>% select(sumCO2)

p10 <- fx2100 %>% autoplot(df2) + labs(x = "Time", y = "CO2 Level in Atmosphere (ppm)", title = "CO2 Level in the Atmosphere Based on Linear Time Trend Model")
p11 <- ari.fit %>% forecast(h = 1236) %>% filter(.model == "ARIMA013011") %>% autoplot(df) + labs(x = "Time", y = "CO2 Level in Atmosphere (ppm)", title = "CO2 Level in the Atmosphere Based on ARIMA Model")

grid.arrange(p10, p11, nrow = 2, ncol = 1)
```
The team generated forecast from 1998 to 2100. Based of the generated forecast, for the linear model, the CO2 level at Mauna Loa is expected to reach 420 ppm the first time in `r fx2100.avg420.lm1` and last time in `r fx2100.avg420.lm2`. However, based on the 90% CI band, we may observe the CO2 level to reach 420 ppm as early as in `r fx2100.1st420.lm` and may see it again the last time in `r fx2100.lst420.lm`. Also, according to the linear model, the CO2 level at Mauna Loa is expected to reach 500 ppm the first time in `r fx2100.avg500.lm1` and last time in `r fx2100.avg500.lm2`. But based on its 90% CI, we may observe the CO2 level to reach 500 ppm as early as `r fx2100.1st500.lm` and may see it again the last time in `r fx2100.lst500.lm`. 

For the ARIMA model, the CO2 level is expected to reach 420 ppm the first time in `r fx2100.avg420.ari1` and last time in `r fx2100.avg420.ari2`. Based on its 90% CI, we may observe the CO2 level to reach 420 ppm as early as in `r fx2100.1st420.ari` and may see it again the last time in `r fx2100.lst420.ari`. The CO2 level is expected to reach 500 ppm the first time in `r fx2100.avg500.ari1` and last time in `r fx2100.avg500.ari2`. Based on its 90% CI, we may observe the CO2 level to reach 500 ppm as early as `r fx2100.1st500.lm` and may come back again to this level after the last time step of the forecast horizon, which is `r fx2100.lst500.ari`.

In 2100, based on the linear model, the CO2 level at Mauno Loa is expected to reach `r fx2100.lm` ppm for the linear model and `r fx2100.ari` ppm for the ARIMA model. The ARIMA model suggests a slower growth of CO2 level and also has a wider 90% CI, than the predictions from the linear model. 

Athough it is unlikely both models would provide accurate CO2 levels in 2100 (given they do not account for changing external trends), one model can be closer in its prediction than the other model. ARIMA models are stochastic models and by their essence are generally inadequate for long-term forecasting, such as more than a few months ahead. This fact is reflected by its growing band of confidence interval with time. The LTTM is a deterministic model that depends heavily on an underlying process and if the process generating the data changes, the model will continue to forecast based on the original process. If the underlying reason for CO2 emissions is deterministic, then our team does not reasonably expect the trend to change drastically and thus we would have more confidence in the LTTM prediction. We can only determine which model is better, and also, if the CO2 emissions trend is a stochastic or deterministic, by measuring their forecasting. The statical diagnostics in our analysis lean towards favoring the ARIMA model and hence a stochastic trend.  

# Report from the Point of View of the Present 
## Introduction 

Having journeyed through the historical perspective presented in our 1997 report, we now stand at the present, armed with updated data and refined tools. However, the severity of CO2 levels in the near future is not known with certainty due to the uncertainty that accompanies long-term forecasts, especially those extending to the year 2100. In the following sections, the team decided to reevaluate the CO2 forecast provided in 1997 and update our forecast conducted in 1997 with more recent data. 
In the process of this work, we also aim to identify any systematic changes in the way CO2 level grows at Mauna Loa. 

## Modern data Exploration

With the backdrop of our historical analysis, we turn our attention to the contemporary state of CO2 levels at Mauna Loa. Employing a methodology similar to our 1997 study, our team conducted EDA of the most recent data. This process involved meticulous steps to ensure the integrity of the data, starting with the removal of faulty values—negative readings and suspicious outliers. 

### Unraveling Weekly CO2 Trends
```{r present data pipeline and processing, echo = FALSE}
url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv" 
co2_present <- read_csv(url, skip = 35)
co2_present <- co2_present %>% select(year, month, day, average)

# Processing data
co2_present <- co2_present %>% mutate(
  time_index = lubridate::make_date(year, month, day),
  value = case_when(average < 0 ~  NA, 
                      average >= 0 ~ average)
) %>% fill(value, .direction = "up") %>% as_tsibble(index = time_index) %>%
  mutate(
    value = round(value, 2),
    log_value = log(value)
  ) %>% select(value, log_value)


co2_present.add <- co2_present %>% model(stl = STL(value))
co2_present.mult <- co2_present %>% model(stl = STL(log_value)) 

p1b1 <- components(co2_present.add) %>% 
  as_tsibble() %>% 
  autoplot(value, colour = "gray") + geom_line(aes(y = trend), color = "#D55E00") + 
  labs(y = "CO2 Part per Million", x = "Time", title = "Weekly CO2 Mole Fraction at Mauna Loa")

p1b2 <- components(co2_present.mult) %>% 
    as_tsibble() %>% 
  autoplot(log_value, colour = "gray") + geom_line(aes(y = trend), color = "#D55E00") + 
  labs(y = "CO2 Part per Million", x = "Time", title = "Log of Weekly CO2 Mole Fraction at Mauna Loa")

grid.arrange(p1b1, p1b2, nrow = 1, ncol = 2)
```
The plot above portrays the weekly CO2 levels at Mauna Loa from May 1974 to October 2023. The left graph displays the raw CO2 levels, while the right graph showcases the logarithmic transformation. Notably, the present-day plot reveals a more pronounced non-linear trend compared to the 1997 study, indicating that the multiplicative decomposition method is better suited to capture the intricacies of the current data.

### Decomposition and Residual Analysis
```{r EDA present, echo = FALSE}
p1b3 <- co2_present.add %>% components() %>% autoplot() 
p1b4 <- co2_present.add %>% components() %>% ACF(remainder) %>% autoplot() + labs(titles = "Residuals of additive composition") 
p1b5 <- co2_present.mult %>% components() %>% autoplot() 
p1b6 <- co2_present.mult %>% components() %>% ACF(remainder) %>% autoplot() + labs(titles = "Residuals of multiplicative composition")

grid.arrange(p1b3, p1b4, p1b5, p1b6, nrow = 2, ncol = 2) 
```
The above plot shows the actual decomposition using the additive and multiplicative method along with the ACF plots of the residuals (after the trend and the seasonal component were removed from the series). The ACF plots show that, at the weekly granularity, the residuals timeseries does not have stationary characteristics, suggesting that further differencing transformation may be needed. 

### Iterative Differencing
Continuing our analysis, the team then performed a series of differencing transformation on the updated dataset. Similarly to the analysis included in the 1997 study, we generated a CO2 timeseries with the differencing at the subsequent lag and every 52 lags to remove the trend and the seasonality component from the data. 

### Identifying Modeling Candidates
The above plots show the timeseries with differencing transformation and their associated ACF and PACF plots. The third plot, which shows the timeseries after the trend and seasonal differencing, indicates that there is no trend or seasonality within the series and suggests an ARIMA model with both seasonal and non-seasonal moving average and autoregressive terms may be a good candidate to model the updated dataset. 

## Linear model forecast assessment
```{r linear model 1997 vs observed, echo = FALSE, warning= FALSE}
co2_present.m1 <- co2_present %>% as_tibble() %>%
  mutate(
  index = yearmonth(time_index) 
) %>% group_by(index) %>% summarise(
 value = mean(value),
 log_value = mean(exp(log_value))
) %>% as_tsibble(index = index) %>% 
  filter(as.Date(index) >= as.Date("2000-01-01") & as.Date(index) < as.Date("2020-12-31"))


fx2020 %>% filter((as.Date(index) > as.Date("2000-01-01")) & (as.Date(index) < as.Date("2020-12-31"))) %>% autoplot(co2_present.m1) + 
  labs(x = "Time", y = "CO2 Level at Mauna Loa", title = "Comparison between 1997 Forecast (Linear Model) with Observed Values") 
```
To gauge the efficacy of our 1997 linear model in predicting present-day CO2 levelsthe forecast, we aggregated the weekly actual CO2 data to monthly data so that the dataset has the same time index as the forecast values. Based on the comparison in the above plot (where the black line shows the observed CO2 level and blue line shows the forecast CO2 level), the 1997 linear model overforecast the CO2 level at Mauna Loa from 2000 to 2020. 

## ARIMA model forecast assessment
```{r ARIMA model 1997 vs observed, echo = FALSE, warning= FALSE}
co2_present.m2 <- co2_present %>% as_tibble() %>%
  mutate(
  index = yearmonth(time_index) 
) %>% group_by(index) %>% summarise(
 value = mean(value),
 log_value = mean(exp(log_value))
) %>% as_tsibble(index = index) %>% 
  filter(as.Date(index) >= as.Date("2000-01-01") & as.Date(index) < as.Date("2022-12-31"))

ari.fit %>% forecast(h = 300) %>% filter(.model == 'ARIMA013011') %>% autoplot(co2_present.m2) + 
    labs(x = "Time", y = "CO2 Level at Mauna Loa", title = "Comparison between 1997 Forecast (ARIMA Model) with Observed Values") 
```
The plot above depicts the comparison between the forecast from the 1997 ARIMA model and observed CO2 level. Intrestingly, the actual CO2 levels are closer to the upper bound of the 95% CI of the 1997 ARIMA forecast. The forecast from 1997 ARIMA model shows that the expected forecast is lower than the observed CO2 values at a more significant degree than that of the linear model. However, the observed CO2 still appears to be closer to the upper bound of the 95% CI of the ARIMA model. 

## Performance of 1997 linear and ARIMA models 

```{r Performance evaluation - reach 420ppm, echo = FALSE, warning= FALSE} 
obs1st420 <- co2_present %>% filter(value >= 420) %>% filter(row_number() ==1) %>% select(time_index) 
```
The observed CO2 values indicate that the CO2 level reached 420 ppm the first time in `r obs1st420`. This is earlier than the prediction from the linear model and later than the prediction from the ARIMA model. The linear model (with a tight CI band) predicted that the CO2 level would reach 420 ppm as early as in `r fx2100.1st420.lm`, while the ARIMA model predicted that the CO2 level would reach 420 ppm as early as in `r fx2100.1st420.ari`. Based on their prediction, the ARIMA model provided a more accurate expectation than the linear model. Please refer to the appendix for an elaboration on the metrics used to assess the models. 

## Improved Model using New Data
Using the addition of new data and the insights we gained from evaluating 1997 modes, we can retrain the ARIMA model for enhanced accuracy.
```{r generate training and testing data, echo = FALSE, warning = FALSE}
co2_present.m4 <- co2_present %>% as_tibble() %>%
  mutate(
  index = yearmonth(time_index) 
) %>% group_by(index) %>% summarise(
 value = mean(value),
 log_value = mean(log_value)
) %>% as_tsibble(index = index) 
co2.log.tr <- co2_present.m4 %>% model(stl = STL(log_value)) %>% components() %>% slice(1:(n()-24)) %>% as_tsibble(index = index) 
co2.log.sa.tr <- co2.log.tr %>% select(season_adjust)
co2.log.nsa.tr <- co2.log.tr %>% select(log_value)
co2.log.te <- co2_present.m4 %>% model(stl = STL(log_value)) %>% components() %>% slice((n()-24):n()) %>% as_tsibble(index = index)
co2.log.sa.te <- co2.log.te %>% select(season_adjust)
co2.log.nsa.te <- co2.log.te %>% select(log_value)

# Seasonally adjusted models 
ari.fit2 <- co2.log.sa.tr %>% 
  model(ARIMA111101 = ARIMA(season_adjust ~ pdq(1,1,1) + PDQ(1,0,1)),
        ARIMA111201 = ARIMA(season_adjust  ~ pdq(1,1,1) + PDQ(2,0,1)),
        ARIMA211201 = ARIMA(season_adjust  ~ pdq(2,1,1) + PDQ(2,0,1)),
        ARIMA112102 = ARIMA(season_adjust  ~ pdq(1,1,2) + PDQ(1,0,2)), 
        ARIMA112101 = ARIMA(season_adjust ~ pdq(1,1,2) + PDQ(1,0,1)),
        ARIMA111102 = ARIMA(season_adjust  ~ pdq(1,1,1) + PDQ(1,0,2)),
        ARIMA013001 = ARIMA(season_adjust ~ pdq(0,1,3) + PDQ(0,0,1)),
        auto = ARIMA(season_adjust, stepwise = FALSE, approx = FALSE)
        )

ari.fit2 %>% pivot_longer(everything(), names_to = "Model name", values_to = "Orders")

glance(ari.fit2) |> arrange(AICc) |> select(.model:AICc)

mul.quad.sea2 <- co2.log.sa.tr %>% 
  model(trend_model = TSLM(season_adjust ~ trend() + I(trend()^2)))
mul.quad.sea2 %>% report()

future.df2 <- new_data(co2.log.sa.tr, n = 24)
lm.fx.te <- mul.quad.sea2 %>% forecast(new_data = future.df2)


bind_rows(
  ari.fit2 %>% select(ARIMA111201) %>% forecast(h = 24) %>% fabletools::accuracy(co2.log.sa.te),
  ari.fit2 %>% select(ARIMA211201) %>% forecast(h = 24) %>% fabletools::accuracy(co2.log.sa.te),
  ari.fit2 %>% select(ARIMA111102) %>% forecast(h = 24) %>% fabletools::accuracy(co2.log.sa.te), 
  ari.fit2 %>% select(ARIMA111101) %>% forecast(h = 24) %>% fabletools::accuracy(co2.log.sa.te),
  ari.fit2 %>% select(ARIMA013001) %>% forecast(h = 24) %>% fabletools::accuracy(co2.log.sa.te),
  lm.fx.te %>% fabletools::accuracy(co2.log.sa.te)
  
)

# Non-seasonally adjusted models 

ari.fit3 <- co2.log.nsa.tr %>% 
  model(ARIMA111101 = ARIMA(log_value ~ pdq(1,1,1) + PDQ(1,1,1)),
        ARIMA111201 = ARIMA(log_value  ~ pdq(1,1,1) + PDQ(2,1,1)),
        ARIMA211201 = ARIMA(log_value  ~ pdq(2,1,1) + PDQ(2,1,1)),
        ARIMA112102 = ARIMA(log_value  ~ pdq(1,1,2) + PDQ(1,1,2)), 
        ARIMA112101 = ARIMA(log_value ~ pdq(1,1,2) + PDQ(1,1,1)),
        ARIMA111102 = ARIMA(log_value  ~ pdq(1,1,1) + PDQ(1,1,2)),
        ARIMA013001 = ARIMA(log_value ~ pdq(0,1,3) + PDQ(0,1,1)),
        auto = ARIMA(log_value, stepwise = FALSE, approx = FALSE)
        )

ari.fit3 %>% pivot_longer(everything(), names_to = "Model name", values_to = "Orders")

glance(ari.fit3) |> arrange(AICc) |> select(.model:AICc)


```
The Ljungbox test shows that all ARIMA models that use seasonally-adjusted data had residuals that show some level of serial relationship within the data. This suggests that using seasonally-adjusted data is not as effective as using non-seasonally adjusted data to develop models to fit the CO2 data. 

## Future Predictions

According to the selected model (ARIMA model with one seasonal and non-seasonal difference term, one seasonal and non-seasonal moving average term), the CO2 level is expected to reach 420 ppm first time in `r fx2122.avg420.ari1` and last time in `r fx2122.avg420.ari2`. The 90% CI of the model prediction suggests that we may see the CO2 level reach 420 ppm as early as in `r fx2122.1st420.ari` and may see it again as late as in `r fx2122.lst420.ari`. 

According to the model, the CO2 level is expected to reach 500 ppm. first time in `r fx2122.avg500.ari1` and last time in `r fx2122.avg500.ari2`. The 90% CI of the model prediction suggests that we may see the CO2 level reach 500 ppm as early as in `r fx2122.1st500.ari` and may see it again as late as in `r fx2122.lst500.ari`. 

## Conclusion
Our journey from 1997's historical insights to the contemporary CO2 dynamics at Mauna Loa uncovered both continuities and shifts in atmospheric CO2. Armed with updated data, we aimed to reassess prior forecasts and discern any systematic changes in CO2 growth patterns.

Our prior, 1997 models demonstrated divergence from modern conditions, revealing overforecasting from 2000 to 2020. In the realm of ARIMA models, we observed CO2 levels were near the upper bounds of the 95% confidence interval, hinting at an increase in the underlying contributor sources to atmospheric CO2. The ARIMA forecast consistently projected lower values yet, maintained a proximity to its upper confidence interval.

With insights from 1997 models and new data, our gaze extends to the future. The interplay of forecasts suggests that the ARIMA model, with the addition of seasonal and non-seasonal terms, offers a more accurate prediction of atmospheric CO2. The Ljungbox test underscores the model's efficacy with non-seasonally adjusted data. Looking ahead, our selected ARIMA model predicts a first encounter with a concentration of 420 ppm as early as `r fx2122.avg420.ari1` and a lingering farewell as late as `r fx2122.avg420.ari2`. The anticipation of reaching 500 ppm, a milestone with extreme environmental implications, is also predicted for the future. Here, we acknowledge the inherent uncertainty accompanying long-term projections and hope that un-incorporated factors, such as the adoption of new technologies and carbon mitigation techniques will render our forecasts as worst-case over-predictions. 

## Appendix

### Iterative Differencing Plots
```{r co2 present transformation, echo  = FALSE, warning = FALSE} 
co2_present %>% gg_tsdisplay(log(value), plot_type = 'partial',lag = 104)
co2_present %>% gg_tsdisplay(difference(log(value)), plot_type = 'partial',lag = 104)
co2_present %>% gg_tsdisplay(difference(difference(log(value)), 52), plot_type = 'partial',lag = 104)
```

### Model Performance Metrics
```{r model evaluation, echo = FALSE, warning = FALSE}
co2_present.m3 <- co2_present %>% as_tibble() %>%
  mutate(
  index = yearmonth(time_index) 
) %>% group_by(index) %>% summarise(
 value = mean(value),
 log_value = mean(exp(log_value))
) %>% as_tsibble(index = index) 

bind_rows(
  ari.fit %>% select(ARIMA013011) %>% forecast(h = 300) %>% fabletools::accuracy(co2_present.m3),
  ari.fit %>% select(ARIMA211211) %>% forecast(h = 300) %>% fabletools::accuracy(co2_present.m3),
  ari.fit %>% select(ARIMA111211) %>% forecast(h = 300) %>% fabletools::accuracy(co2_present.m3), 
  ari.fit %>% select(ARIMA111111) %>% forecast(h = 300) %>% fabletools::accuracy(co2_present.m3),
  ari.fit %>% select(ARIMA112111) %>% forecast(h = 300) %>% fabletools::accuracy(co2_present.m3),
  fx2020 %>% fabletools::accuracy(co2_present.m3)
)
```
The team calculated the performance metrics in order to evaluate the performance of the models that we developed in 1997. The performance metrics include but are not limited to root mean square error, mean absolute error and mean absolute percentage error. Based on the results of the metrics table, the linear model with trend (linear and quadratic terms) and seasonal terms was the best model with the lowest score in all metrics. 


